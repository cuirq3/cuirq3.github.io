<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> | Ruiqi Cui | 崔睿琦 </title> <meta name="author" content="Ruiqi Cui | 崔睿琦"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cuirq3.github.io/projects/siga_24/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ruiqi</span> Cui | 崔睿琦 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"></h1> <p class="post-description"></p> </header> <article> <div class="detail_ct"> <h2 class="rd_title">Surface Reconstruction Using Rotation Systems</h2> <p class="td_text"></p> <div class="rd_ct">&lt;p font-size:12px="" style="text-align: center;"&gt;<span style="font-size:18px;"><span style="font-family:Arial,Helvetica,sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2024)</span></span>&lt;/p&gt; &lt;p font-size:12px="" style="text-align: center;"&gt;<span style="font-family:Arial,Helvetica,sans-serif;"><strong><span style="font-size:14px">​</span></strong></span>&lt;/p&gt; &lt;p font-size:12px="" style="text-align: center;"&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Yilin Liu<sup>1</sup>    Ruiqi Cui<sup>1</sup>    <a data-ke-src="https://vcc.tech/~kexie" href="https://vcc.tech/~kexie" target="_blank" rel="external nofollow noopener">Ke Xie</a><sup>1</sup>    <a data-ke-src="http://socs.uoguelph.ca/~minglun/" href="http://socs.uoguelph.ca/~minglun/" target="_blank" rel="external nofollow noopener">Minglun Gong</a><sup>2</sup>    <a data-ke-src="https://vcc.tech/~huihuang" href="https://vcc.tech/~huihuang" target="_blank" rel="external nofollow noopener">Hui Huang</a><sup>1*</sup></span></span>&lt;/p&gt; &lt;p font-size:12px="" style="text-align: center;"&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;"><sup>1</sup>Shenzhen University    <sup>2</sup>University of Guelph</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222316692.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083784725.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 1. Given an unknown large-scale urban site with arbitrary boundary shape (red polygon shown on left), our algorithm designs an aerial flight trajectory in real-time, which guides a single-camera UAV to both explore the site (trajectory shown in yellow) and observe all buildings (trajectory shown in blue). 9,148 images were captured, which support high-quality reconstruction of this 1.35km<sup>2</sup> area through available multi-view stereo matching techniques (right).</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:18px;"><span style="font-family:Arial,Helvetica,sans-serif;"><strong>Abstract</strong></span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Existing approaches have shown that, through carefully planning flight trajectories, images captured by Unmanned Aerial Vehicles (UAVs) can be used to reconstruct high-quality 3D models for real environments. These approaches greatly simplify and cut the cost of large-scale urban scene reconstruction. However, to properly capture height discontinuities in urban scenes, all state-of-the-art methods require prior knowledge on scene geometry and hence, additional prepossessing steps are needed before performing the actual image acquisition flights. To address this limitation and to make urban modeling techniques even more accessible, we present a real-time explore-and-reconstruct planning algorithm that does not require any prior knowledge for the scenes. Using only captured 2D images, we estimate 3D bounding boxes for buildings on-the-fly and use them to guide online path planning for both scene exploration and building observation. Experimental results demonstrate that the aerial paths planned by our algorithm in real-time for unknown environments support reconstructing 3D models with comparable qualities and lead to shorter flight air time.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222337683.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083809455.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 2. Overview: Taking the live feed video from a UAV on an appointed site as input, our system detects buildings and estimates their bounding boxes (e.g., the first model in the top row), which guide the UAV to further explore the site (yellow trajectory) and observe buildings from different perspectives (blue trajectory). Additional observations further enhance our knowledge on this site, allowing more buildings being detected and modeled as boxes (remaining models in the top row). At the end of the flight, the captured image sequence (middle) is used to build a high-quality model for the whole scene (bottom).</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222384273.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083824774.png" style="width: 1300px; height: 196px;">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 4. The proposed Region-Division method for global scene exploration. a): At the beginning, the UAV only knows the boundary of the whole area. A (green) region is defined using a default size ∈ for the UAV to explore. During the exploration, the UAV discovers target building 1, 2, 3 through the perception distance of two cells by default. It switches to reconstruction mode once it arrives at the cells of building 1, 2, but leaves building 3 for the latter processing since it locates outside the green region. b): The target building 3 will guide the formation of the next (blue) region. c): Since no new building is detected during the exploration of the blue region, the next (yellow) region to be explored is defined using size ∈ again. Buildings 4, 5 detected and reconstructed during the exploration of the yellow region. d): The final path generated by Region-Division divides the whole site into four non-overlapping polygon-shaped regions. It ensures all cells are explored and all buildings are observed. The total path length (22,114) is shorter than the two baselines (Greedy-Nearest: 23,852 and Two-Step: 25,170); see Supplementary for further details.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222408608.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083838760.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 5. Local path planning for target building reconstruction. A set of simple rules are used so that the planning can be done in real-time and adapt to new observations. The trajectories are initialized based on the shape of the building’s bounding box (left) and deformed when the bounding box changes or potential collusion is detected (right).</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222429699.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083859877.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 8. We show on the left a real scene referred to as Academic Building. As illustrated, a single 3D orientated bounding box cannot fit the target building tightly and thus may lose many important geometry details especially in the concave areas. On the right, we show an ablation study that uses different trajectories to observe the buildings: a) 80% overlap trajectory with split strategy nicely covers all areas of the buildings and hence produces the best model; b) 80% overlap trajectory without split yields shortest flight path, but the samples are not enough for accurate reconstruction; and c) 60% overlap trajectory with split strategy has similar path length as b), but noticeable better reconstruction result.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222882593.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083877761.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 11. Comparison on flight trajectories and reconstruction results on Academic Building. Our approach achieve similar reconstruction quality as the offline optimization-based approach [Zhou et al. 2020], while using much smoother flight trajectories. Note that the trajectory of Oblique Photography covers a larger area to ensure the sufficient image overlap on buildings near the boundary. This is a default behavior in Dji-Terra.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222902546.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083897972.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 14. Visualizing the trajectories designed by the two baseline approaches and the proposed Region-Division method. Our approach decomposes the scene into non-overlapping regions, which can be handled independently.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1651222923587.png"><img alt="" src="https://vcc-szu.s3.ap-southeast-1.amazonaws.com/1659083915214.png">&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">Fig. 16. Visual comparison with Oblique Photography on a real large-scale Campus scene. Our approach decompose this large (1.35km<sup>2</sup>) and irregular-shaped site into multiple non-overlapping regions (Top-Left). The density of the flight trajectory highly depends on the locations of buildings. The finally reconstructed models are noticeably more detailed than those generated by Oblique Photography.</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:18px;"><span style="font-family:Arial,Helvetica,sans-serif;"><strong>Acknowledgements</strong></span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">We thank all reviewers for their valuable comments. This work was supported in parts by NSFC (U2001206), Guangdong Talent Program (2019JC05X328), Guangdong Science and Technology Program (2020A0505100064), DEGP Key Project (2018KZDXM058), Shenzhen Science and Technology Program (RCJC20200714114435012, JCYJ20210324120213036), NSERC (293127), National Engineering Laboratory for Big Data System Computing Technology, and Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ).</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt; &lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:18px;"><span style="font-family:Arial,Helvetica,sans-serif;"><strong>Bibtex</strong></span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">@article{DroneFly21,</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">title={Aerial Path Planning for Online Real-Time Exploration and Offline High-Quality Reconstruction of Large-Scale Urban Scenes},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">author={Yilin Liu and Ruiqi Cui and Ke Xie and Minglun Gong and Hui Huang},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">journal={ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">volume={40},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">number={6},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">pages={226:1--226:16},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">year={2021},</span></span>&lt;/p&gt; &lt;p font-size:12px=""&gt;<span style="font-size:14px;"><span style="font-family:Arial,Helvetica,sans-serif;">}</span></span>&lt;/p&gt; </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Ruiqi Cui | 崔睿琦. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: November 05, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>